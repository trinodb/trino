connector.name=delta_lake

# Configuration appropriate for Hive as started by product test environment, e.g.
#  testing/bin/ptl env up --environment multinode-minio-data-lake --without-trino
# On Mac, this additionally requires that you add "<your external IP> hadoop-master" to /etc/hosts
hive.metastore.uri=thrift://localhost:9083

# `default` schema has hdfs location. Configuring socks proxy allows creating tables
# without specifying s3://... location for each of them (obviously MinIO won't be used for that).
hive.hdfs.socks-proxy=localhost:1180

# MinIO uses 9000 by default, but this change conflicts with Hadoop
hive.s3.endpoint=http://localhost:9080
hive.s3.path-style-access=true
hive.s3.ssl.enabled=false
hive.s3.aws-access-key=minio-access-key
hive.s3.aws-secret-key=minio-secret-key

# Fail-fast in development
hive.metastore.thrift.client.max-retry-time=1s
hive.s3.max-client-retries=1
# Enable write support for all supported file systems in development
delta.enable-non-concurrent-writes=true
