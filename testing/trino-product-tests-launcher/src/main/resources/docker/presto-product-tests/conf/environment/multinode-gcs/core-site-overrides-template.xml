<configuration>
    <property>
        <!-- Required to enable full schema evolution. See https://github.com/apache/iceberg/issues/1092#issuecomment-638432848 -->
        <name>hive.metastore.disallow.incompatible.col.type.changes</name>
        <value>false</value>
    </property>

    <!-- Google Cloud Storage properties -->
    <property>
        <name>fs.gs.impl</name>
        <value>com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem</value>
        <description>The FileSystem for gs: (GCS) uris.</description>
    </property>

    <property>
        <name>fs.AbstractFileSystem.gs.impl</name>
        <value>com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS</value>
        <description>
            The AbstractFileSystem for gs: (GCS) uris. Only necessary for use with Hadoop 2.
        </description>
    </property>

    <property>
        <name>google.cloud.auth.service.account.enable</name>
        <value>true</value>
        <description>
            Whether to use a service account for GCS authorizaiton. If an email and
            keyfile are provided (see google.cloud.auth.service.account.email and
            google.cloud.auth.service.account.keyfile), then that service account
            willl be used. Otherwise the connector will look to see if it running on
            a GCE VM with some level of GCS access in it's service account scope, and
            use that service account.
        </description>
    </property>

    <property>
        <name>google.cloud.auth.service.account.json.keyfile</name>
        <value>%GCP_CREDENTIALS_FILE_PATH%</value>
        <description>
            The JSON key file of the service account used for GCS
            access when google.cloud.auth.service.account.enable is true.
        </description>
    </property>
</configuration>
